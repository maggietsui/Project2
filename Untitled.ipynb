{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\"\"\"\n",
    "algs.py\n",
    "====================================\n",
    "Classes and methods for project 2\n",
    "\"\"\"\n",
    "class Ligand():\n",
    "    \"\"\"Class that stores data about ligands including LigandID, score, SMILES, on bits\"\"\"\n",
    "    def __init__(self, ID, score, SMILES, onbits):\n",
    "        \"\"\"\n",
    "        Initialize ligand object\n",
    "        Parameters\n",
    "        ---------\n",
    "        ID\n",
    "            Path to csv with ligand info\n",
    "        score\n",
    "        SMILES\n",
    "        onbits\n",
    "        \"\"\"\n",
    "        self._ID = ID\n",
    "        self._score = score\n",
    "        self._SMILES = SMILES\n",
    "        self._onbits = onbits\n",
    "\n",
    "    @property\n",
    "    def ID(self):\n",
    "        return self._ID\n",
    "    \n",
    "    @ID.setter\n",
    "    def ID(self, ID):\n",
    "        self._ID = ID\n",
    "\n",
    "    @property\n",
    "    def score(self):\n",
    "        return self._score\n",
    "    \n",
    "    @score.setter\n",
    "    def score(self, score):\n",
    "        self._score = score\n",
    "\n",
    "    @property\n",
    "    def SMILES(self):\n",
    "        return self._SMILES\n",
    "    \n",
    "    @SMILES.setter\n",
    "    def SMILES(self, SMILES):\n",
    "        self._SMILES = SMILES\n",
    "\n",
    "    @property\n",
    "    def onbits(self):\n",
    "        return self._onbits\n",
    "    \n",
    "    @onbits.setter\n",
    "    def onbits(self, onbits):\n",
    "        self._onbits = onbits\n",
    "\n",
    "   \n",
    "class Clustering():\n",
    "    \"\"\"Base class for clustering\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Blah blah blah.\n",
    "        Parameters\n",
    "        ---------\n",
    "        name\n",
    "            A string to assign to the `name` instance attribute.\n",
    "        \"\"\"\n",
    "\n",
    "    def get_ligands(self, n):\n",
    "        \"\"\"\n",
    "        Gets the first n ligands from the csv\n",
    "        Parameters\n",
    "        ---------\n",
    "        n\n",
    "            Number of ligands to return\n",
    "\n",
    "        Returns: dictionary where keys are ligand IDs\n",
    "        and values are ligand objects\n",
    "        \"\"\"\n",
    "        table = pd.read_csv(\"./ligand_information.csv\")\n",
    "        ligands = {}\n",
    "        for i in range(n):\n",
    "            onbits = list(map(int, table.iloc[i]['OnBits'].split(\",\")))\n",
    "            score = table.iloc[i]['Score']\n",
    "            smiles = table.iloc[i]['SMILES']\n",
    "            lig = Ligand(i,score,smiles,onbits)\n",
    "            ligands[i] = lig\n",
    "\n",
    "        return ligands\n",
    "\n",
    "    def calculate_distance(self, A, B):\n",
    "        \"\"\"\n",
    "        The jaccard index takes the intersect of onbits over\n",
    "        the union of onbits. Distance here is 1 - jaccard index \n",
    "        Parameters\n",
    "        ---------\n",
    "        A\n",
    "            list of onbits for first ligand\n",
    "        B\n",
    "            list of onbits for second ligand\n",
    "\n",
    "        Returns: distance between two ligands\n",
    "        \"\"\"\n",
    "        return 1 - len(set(A) & set(B))/len(set(A+B))\n",
    "\n",
    "class HierarchicalClustering(Clustering):\n",
    "    \"\"\"Implementation of HC using single linkage\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Class that implements hierarchical clustering using single\n",
    "        linkage\n",
    "        Parameters\n",
    "        ---------\n",
    "        n_clusters\n",
    "            Default 1. Stops clustering when algorithm reaches\n",
    "            n_clusters\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def cluster(self, ligands, k=1):\n",
    "        \"\"\"\n",
    "        Method that takes a set of ligands and clusters them\n",
    "        Parameters\n",
    "        ---------\n",
    "        ligands\n",
    "            dict where keys are ligand IDs and values are ligands\n",
    "        k\n",
    "            number of clusters to stop at\n",
    "        Returns: Dictionary of clusters with assigned ligands\n",
    "        \"\"\"\n",
    "        # Initialize cluster list\n",
    "        clusters = []\n",
    "        for key in ligands.keys():\n",
    "            clusters.append([key]) # put all ligands in their own cluster\n",
    "\n",
    "        # Initialize distance matrix\n",
    "        dist = np.full((len(ligands),len(ligands)), float(\"inf\"))\n",
    "\n",
    "        # loop through bottom half of matrix and fill in distances\n",
    "        for i in range(len(ligands)):\n",
    "            for j in range(len(ligands)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                dist[i,j] = self.calculate_distance(ligands[i].onbits,ligands[j].onbits)\n",
    "\n",
    "        while len(clusters) > k:\n",
    "            # find min \n",
    "            min_i, min_j = np.unravel_index(np.argmin(dist), dist.shape)\n",
    "\n",
    "            # find the two ligands in clusters\n",
    "            found_i = -1\n",
    "            found_j = -1\n",
    "            for idx in range(len(clusters)):\n",
    "                #if found_i >= 0 and if found_j >= 0:\n",
    "                 #   break\n",
    "                if found_i < 0 and min_i in clusters[idx]:\n",
    "                    found_i = idx\n",
    "                if found_j < 0 and min_j in clusters[idx]:\n",
    "                    found_j = idx\n",
    "\n",
    "            # merge the clusters\n",
    "            clusters[found_i]+= clusters[found_j]\n",
    "            del clusters[found_j]\n",
    "\n",
    "\n",
    "            # update distance matrix using single linkage\n",
    "            for idx in range(len(ligands)):\n",
    "                if dist[min_i, idx] == np.inf: #\n",
    "                    continue\n",
    "                minimum = min(dist[min_i, idx], dist[min_j,idx])\n",
    "                dist[min_i, idx] = minimum\n",
    "                dist[idx, min_i] = minimum\n",
    "\n",
    "            dist[min_j, :] = np.inf\n",
    "            dist[:, min_j] = np.inf\n",
    "        \n",
    "        return clusters\n",
    "\n",
    "\n",
    "class PartitionClustering(Clustering):\n",
    "    \"\"\"Implementation of partition clustering (kmeans)\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Blah blah blah.\n",
    "        Parameters\n",
    "        ---------\n",
    "        name\n",
    "            A string to assign to the `name` instance attribute.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def cluster(self, ligands, k):\n",
    "        \"\"\"\n",
    "        Method that takes a set of ligands and clusters them\n",
    "        Parameters\n",
    "        ---------\n",
    "        ligands\n",
    "            dict where keys are ligand IDs and values are ligands\n",
    "        k\n",
    "            number of clusters to initialize\n",
    "        Returns: List clusters with assigned ligands\n",
    "        \"\"\"\n",
    "        # choose k random ligands as centroids\n",
    "        clusters = random.sample(range(len(ligands)), k)\n",
    "        centroids = []\n",
    "        for i in range(k):\n",
    "            centroids.append(ligands[clusters[i]].onbits)\n",
    "            clusters[i] = [clusters[i]]\n",
    "        \n",
    "        same_clusters = False\n",
    "        same_iterations = 0\n",
    "        old_clusters = copy.deepcopy(clusters)\n",
    "        \n",
    "\n",
    "        # Recompute centroids until they clusters haven't changed for 2 iterations\n",
    "        while same_clusters == False:\n",
    "            new_clusters = copy.deepcopy(clusters)\n",
    "            new_centroids = copy.deepcopy(centroids)\n",
    "            print(new_clusters)\n",
    "            print(new_centroids)\n",
    "            for ligand in ligands.keys(): # Loop through ligands\n",
    "                distances = []\n",
    "                # Compute distance to each centroid\n",
    "                for centroid in centroids:\n",
    "                    dist = pc.calculate_distance(ligands[ligand].onbits, centroid)\n",
    "                    distances.append(dist)\n",
    "\n",
    "                # assign ligand to cluster with min distance (tie breaking?)\n",
    "                closest = distances.index(min(distances))\n",
    "                new_clusters[closest].append(ligand)\n",
    "                new_clusters[closest] = list(set(new_clusters[closest]))\n",
    "\n",
    "                # Add onbits to new centroids\n",
    "                new_centroids[closest].extend(ligands[ligand].onbits)\n",
    "                new_centroids[closest] = list(set(new_centroids[closest]))\n",
    "\n",
    "            # recalculate centroids \n",
    "            centroids = copy.deepcopy(new_centroids)\n",
    "\n",
    "            # Keep track of how many times the clusters have not changed\n",
    "            if new_clusters == old_clusters:\n",
    "                same_iterations += 1\n",
    "            if same_iterations == 4:\n",
    "                same_clusters = True\n",
    "\n",
    "            old_clusters = copy.deepcopy(new_clusters)\n",
    "            \n",
    "            print(new_clusters)\n",
    "            print(new_centroids)\n",
    "        return new_clusters\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [7]]\n",
      "[[360, 489, 915], [33, 397, 650, 807, 893, 1017]]\n",
      "[[0, 3], [1, 2, 4, 5, 6, 7, 8, 9]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0], [7]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0, 3], [1, 2, 4, 5, 6, 7, 8, 9]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0], [7]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0, 3], [1, 2, 4, 5, 6, 7, 8, 9]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0], [7]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0, 3], [1, 2, 4, 5, 6, 7, 8, 9]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0], [7]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n",
      "[[0, 3], [1, 2, 4, 5, 6, 7, 8, 9]]\n",
      "[[674, 291, 260, 807, 360, 489, 915, 790], [386, 650, 397, 785, 33, 36, 294, 807, 53, 696, 967, 202, 715, 332, 460, 80, 979, 725, 342, 222, 229, 623, 1017, 893]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 3], [1, 2, 4, 5, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = PartitionClustering()\n",
    "\n",
    "ligands = pc.get_ligands(10)\n",
    "pc.cluster(ligands,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose k random ligands as centroids\n",
    "clusters = random.sample(range(len(ligands)), k)\n",
    "centroids = []\n",
    "for i in range(k):\n",
    "    centroids.append(ligands[clusters[i]].onbits)\n",
    "    clusters[i] = [clusters[i]]\n",
    "\n",
    "same_clusters = False\n",
    "same_iterations = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[260, 291, 360, 674, 790, 807], [53, 623, 650]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3], [1]]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters = copy.deepcopy(clusters)\n",
    "new_centroids = copy.deepcopy(centroids)\n",
    "\n",
    "for ligand in ligands.keys(): # Loop through ligands\n",
    "    distances = []\n",
    "    # Compute distance to each centroid\n",
    "    for centroid in centroids:\n",
    "        dist = pc.calculate_distance(ligands[ligand].onbits, centroid)\n",
    "        distances.append(dist)\n",
    "\n",
    "    # skip starting centroids\n",
    "    if min(distances) == 0:\n",
    "        continue\n",
    "\n",
    "    # assign ligand to cluster with min distance (tie breaking?)\n",
    "    closest = distances.index(min(distances))\n",
    "    new_clusters[closest].append(ligand)\n",
    "\n",
    "    # Add onbits to new centroids\n",
    "    new_centroids[closest].extend(ligands[ligand].onbits)\n",
    "    new_centroids[closest] = list(set(new_centroids[closest]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_clusters = clusters.copy()\n",
    "# recalculate centroids \n",
    "centroids = new_centroids\n",
    "\n",
    "# Keep track of how many times the clusters have not changed\n",
    "if new_clusters == old_clusters:\n",
    "    same_iterations += 1\n",
    "if same_iterations == 2:\n",
    "    same_clusters = True\n",
    "\n",
    "old_clusters = new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(\n",
    "    n_clusters=2, init='random',\n",
    "    n_init=10, max_iter=300, \n",
    "    tol=1e-04, random_state=0\n",
    ")\n",
    "y_km = km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 0, 5, 6], [1, 2, 4, 7, 8, 9]]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33, 674, 291, 260, 386, 294, 807, 360, 489, 229, 460, 80, 915, 790, 222],\n",
       " [33,\n",
       "  36,\n",
       "  967,\n",
       "  807,\n",
       "  650,\n",
       "  715,\n",
       "  332,\n",
       "  397,\n",
       "  202,\n",
       "  623,\n",
       "  785,\n",
       "  979,\n",
       "  53,\n",
       "  342,\n",
       "  725,\n",
       "  696,\n",
       "  1017,\n",
       "  893]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3], [1]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "new_clusters = copy.deepcopy(clusters)\n",
    "new_clusters[1].append(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3], [0, 4]]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HierarchicalClustering()\n",
    "\n",
    "ligands = hc.get_ligands(4)\n",
    "\n",
    "pend([key])\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ligands)):\n",
    "    for j in range(len(ligands)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        dist[i,j] = hc.calculate_distance(ligands[i],ligands[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_i, min_j = np.unravel_index(np.argmin(dist), dist.shape)\n",
    "min_i, min_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the two ligands in clusters\n",
    "found_i = -1\n",
    "found_j = -1\n",
    "for idx in range(len(clusters)):\n",
    "    if (found_i >= 0 and found_j >= 0):\n",
    "        break\n",
    "    if found_i < 0 and min_i in clusters[idx]:\n",
    "        found_i = idx\n",
    "    if found_j < 0 and min_j in clusters[idx]:\n",
    "        found_j = idx\n",
    "\n",
    "# merge the clusters\n",
    "clusters[found_i]+= clusters[found_j]\n",
    "del clusters[found_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(ligands)):\n",
    "    if dist[min_i, idx] == np.inf:\n",
    "        continue\n",
    "    minimum = min(dist[min_i, idx], dist[min_j,idx])\n",
    "    dist[min_i, idx] = minimum\n",
    "    dist[idx, min_i] = minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[min_j, :] = np.inf\n",
    "dist[:, min_j] = np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HierarchicalClustering()\n",
    "\n",
    "ligands = hc.get_ligands(10)\n",
    "\n",
    "c = hc.cluster(ligands, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3], [1, 2, 4, 7, 8, 9, 5, 6]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "dist = np.zeros((len(ligands),len(ligands)))\n",
    "for i in range(len(ligands)):\n",
    "    for j in range(len(ligands)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        dist[i,j] = hc.calculate_distance(ligands[i],ligands[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(affinity=\"precomputed\", n_clusters=5,linkage=\"single\").fit_predict(dist)\n",
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(clustering == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
