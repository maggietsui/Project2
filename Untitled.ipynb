{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from scipy.special import comb\n",
    "\n",
    "\"\"\"\n",
    "algs.py\n",
    "====================================\n",
    "Classes and methods for project 2\n",
    "\"\"\"\n",
    "class Ligand():\n",
    "    \"\"\"Class that stores data about ligands including LigandID, score, SMILES, on bits\"\"\"\n",
    "    def __init__(self, ID, score, SMILES, onbits):\n",
    "        \"\"\"\n",
    "        Initialize ligand object\n",
    "        Parameters\n",
    "        ---------\n",
    "        ID\n",
    "            Path to csv with ligand info\n",
    "        score\n",
    "        SMILES\n",
    "        onbits\n",
    "        \"\"\"\n",
    "        self._ID = ID\n",
    "        self._score = score\n",
    "        self._SMILES = SMILES\n",
    "        self._onbits = onbits\n",
    "\n",
    "    @property\n",
    "    def ID(self):\n",
    "        return self._ID\n",
    "    \n",
    "    @ID.setter\n",
    "    def ID(self, ID):\n",
    "        self._ID = ID\n",
    "\n",
    "    @property\n",
    "    def score(self):\n",
    "        return self._score\n",
    "    \n",
    "    @score.setter\n",
    "    def score(self, score):\n",
    "        self._score = score\n",
    "\n",
    "    @property\n",
    "    def SMILES(self):\n",
    "        return self._SMILES\n",
    "    \n",
    "    @SMILES.setter\n",
    "    def SMILES(self, SMILES):\n",
    "        self._SMILES = SMILES\n",
    "\n",
    "    @property\n",
    "    def onbits(self):\n",
    "        return self._onbits\n",
    "    \n",
    "    @onbits.setter\n",
    "    def onbits(self, onbits):\n",
    "        self._onbits = onbits\n",
    "\n",
    "   \n",
    "class Clustering():\n",
    "    \"\"\"Base class for clustering\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Blah blah blah.\n",
    "        Parameters\n",
    "        ---------\n",
    "        name\n",
    "            A string to assign to the `name` instance attribute.\n",
    "        \"\"\"\n",
    "\n",
    "    def get_ligands(self, n):\n",
    "        \"\"\"\n",
    "        Gets the first n ligands from the csv\n",
    "        Parameters\n",
    "        ---------\n",
    "        n\n",
    "            Number of ligands to return\n",
    "\n",
    "        Returns: dictionary where keys are ligand IDs\n",
    "        and values are ligand objects\n",
    "        \"\"\"\n",
    "        table = pd.read_csv(\"./ligand_information.csv\")\n",
    "        ligands = {}\n",
    "        for i in range(n):\n",
    "            onbits = list(map(int, table.iloc[i]['OnBits'].split(\",\")))\n",
    "            score = table.iloc[i]['Score']\n",
    "            smiles = table.iloc[i]['SMILES']\n",
    "            lig = Ligand(i,score,smiles,onbits)\n",
    "            ligands[i] = lig\n",
    "\n",
    "        return ligands\n",
    "\n",
    "    def calculate_distance(self, A, B):\n",
    "        \"\"\"\n",
    "        The jaccard index takes the intersect of onbits over\n",
    "        the union of onbits. Distance here is 1 - jaccard index \n",
    "        Parameters\n",
    "        ---------\n",
    "        A\n",
    "            list of onbits for first ligand\n",
    "        B\n",
    "            list of onbits for second ligand\n",
    "\n",
    "        Returns: distance between two ligands\n",
    "        \"\"\"\n",
    "        return 1 - len(set(A) & set(B))/len(set(A+B))\n",
    "    \n",
    "    def distance_matrix(self, ligands):\n",
    "        \"\"\"\n",
    "        Computes distance matrix for a set of ligands\n",
    "        Parameters\n",
    "        ---------\n",
    "        ligands\n",
    "            A dict where keys are ligandIDs and values\n",
    "            are ligands\n",
    "        Returns: distance matrix\n",
    "        \"\"\"\n",
    "        # Initialize distance matrix\n",
    "        dist = np.full((len(ligands),len(ligands)), float(\"inf\"))\n",
    "\n",
    "        # loop through matrix and fill in distances\n",
    "        for i in range(len(ligands)):\n",
    "            for j in range(len(ligands)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                dist[i,j] = self.calculate_distance(ligands[i].onbits,ligands[j].onbits)\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def silhouette_score(self, ligands, clusters):\n",
    "        \"\"\"\n",
    "        Calculates average silhouette score for a set of clustered\n",
    "        ligands to assess quality. \n",
    "        Parameters\n",
    "        ---------\n",
    "        clusters\n",
    "            A list of clusters to calculate the score for\n",
    "        Returns: Average silhouette score\n",
    "        \"\"\"\n",
    "        # Initialize distance matrix\n",
    "        dist_mat = self.distance_matrix(ligands)\n",
    "        scores = []\n",
    "        \n",
    "        # loop through each ligand in each cluster\n",
    "        for curr_cluster in range(len(clusters)):\n",
    "            for ligand in clusters[curr_cluster]:\n",
    "                intra_dists = []\n",
    "                mean_inter_dists = []\n",
    "                \n",
    "                # mean distance betw ligand and all members of same cluster\n",
    "                for member in clusters[curr_cluster]:\n",
    "                    if member == ligand:\n",
    "                        continue\n",
    "                    intra_dists.append(dist_mat[ligand,member])\n",
    "                avg_intra = mean(intra_dists)\n",
    "                \n",
    "                # mean distance betw ligand and members of the nearest cluster\n",
    "                # loop through all other clusters\n",
    "                for other_cluster in range(len(clusters)):\n",
    "                    if other_cluster == curr_cluster: # skip current cluster\n",
    "                        continue\n",
    "                    inter_dists = []\n",
    "                    # calculate dist betw ligand and other cluster members\n",
    "                    for member in clusters[other_cluster]:\n",
    "                        inter_dists.append(dist_mat[ligand,member])\n",
    "                    \n",
    "                    mean_inter_dists.append(mean(inter_dists))\n",
    "                    \n",
    "                avg_inter = min(inter_dists) # get mean dist for nearest cluster\n",
    "                score = (avg_inter - avg_intra) / max(avg_inter, avg_intra)\n",
    "                scores.append(score)\n",
    "        \n",
    "        return mean(scores)\n",
    "    \n",
    "    def rand_index(self, ligands,clustering1, clustering2):\n",
    "        \"\"\"\n",
    "        Rand index measures similarity between two sets of clusters.\n",
    "        The Rand index has a value between 0 and 1, with 0 indicating\n",
    "        that the two data clusterings do not agree on any pair of points\n",
    "        and 1 indicating that the data clusterings are exactly the same.\n",
    "        Parameters\n",
    "        ---------\n",
    "        ligands\n",
    "            dict of ligands\n",
    "        clustering1\n",
    "            First set of clusters\n",
    "        clustering2\n",
    "            Second set of clusters\n",
    "        Returns: Rand index for the two sets of clusters\n",
    "        \"\"\"\n",
    "        # Convert list of clusters to list of counts\n",
    "        c1 = [0] * len(ligands)\n",
    "        for i in range(len(clustering1)):\n",
    "            for j in range(len(clustering1[i])):\n",
    "                idx = clustering1[i][j]\n",
    "                c1[idx] = i\n",
    "\n",
    "        c2 = [0] * len(ligands)\n",
    "        for i in range(len(clustering2)):\n",
    "            for j in range(len(clustering2[i])):\n",
    "                idx = clustering2[i][j]\n",
    "                c2[idx] = i\n",
    "\n",
    "        # number of different pairs for each clustering\n",
    "        combos_c1 = comb(np.bincount(c1),2).sum()\n",
    "        combos_c2 = comb(np.bincount(c2),2).sum()\n",
    "\n",
    "        # combine counts into one mat\n",
    "        mat = np.c_[(c1, c2)]\n",
    "\n",
    "        # go through mat and find matching pairs (same\n",
    "        # in both clusterings)\n",
    "        F_11 = 0\n",
    "        for i in range(len(clustering1)):\n",
    "            F_11 += comb(np.bincount(mat[mat[:, 0] == i, 1]), 2).sum()\n",
    "        F_01 = combos_c1 - F_11\n",
    "        F_10 = combos_c2 - F_11\n",
    "        F_00 = comb(len(mat), 2) - F_11 - F_10 - F_01\n",
    "        return (F_11 + F_00)/(F_11 + F_01 + F_10 + F_00)\n",
    "    \n",
    "class HierarchicalClustering(Clustering):\n",
    "    \"\"\"Implementation of HC using single linkage\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Class that implements hierarchical clustering using single\n",
    "        linkage\n",
    "        Parameters\n",
    "        ---------\n",
    "        n_clusters\n",
    "            Default 1. Stops clustering when algorithm reaches\n",
    "            n_clusters\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def cluster(self, ligands, k=1):\n",
    "        \"\"\"\n",
    "        Method that takes a set of ligands and clusters them\n",
    "        Parameters\n",
    "        ---------\n",
    "        ligands\n",
    "            dict where keys are ligand IDs and values are ligands\n",
    "        k\n",
    "            number of clusters to stop at\n",
    "        Returns: Dictionary of clusters with assigned ligands\n",
    "        \"\"\"\n",
    "        # Initialize cluster list\n",
    "        clusters = []\n",
    "        for key in ligands.keys():\n",
    "            clusters.append([key]) # put all ligands in their own cluster\n",
    "\n",
    "        # Initialize distance matrix\n",
    "        dist = self.distance_matrix(ligands)\n",
    "        \n",
    "        while len(clusters) > k:\n",
    "            # find min \n",
    "            min_i, min_j = np.unravel_index(np.argmin(dist), dist.shape)\n",
    "\n",
    "            # find the two ligands in clusters\n",
    "            found_i = -1\n",
    "            found_j = -1\n",
    "            for idx in range(len(clusters)):\n",
    "                #if found_i >= 0 and if found_j >= 0:\n",
    "                 #   break\n",
    "                if found_i < 0 and min_i in clusters[idx]:\n",
    "                    found_i = idx\n",
    "                if found_j < 0 and min_j in clusters[idx]:\n",
    "                    found_j = idx\n",
    "\n",
    "            # merge the clusters\n",
    "            clusters[found_i]+= clusters[found_j]\n",
    "            del clusters[found_j]\n",
    "\n",
    "\n",
    "            # update distance matrix using single linkage\n",
    "            for idx in range(len(ligands)):\n",
    "                if dist[min_i, idx] == np.inf: #\n",
    "                    continue\n",
    "                minimum = min(dist[min_i, idx], dist[min_j,idx])\n",
    "                dist[min_i, idx] = minimum\n",
    "                dist[idx, min_i] = minimum\n",
    "\n",
    "            dist[min_j, :] = np.inf\n",
    "            dist[:, min_j] = np.inf\n",
    "        \n",
    "        return clusters\n",
    "\n",
    "\n",
    "class PartitionClustering(Clustering):\n",
    "    \"\"\"Implementation of partition clustering (kmeans)\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Blah blah blah.\n",
    "        Parameters\n",
    "        ---------\n",
    "        name\n",
    "            A string to assign to the `name` instance attribute.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def cluster(self, ligands, k):\n",
    "        \"\"\"\n",
    "        Method that takes a set of ligands and clusters them\n",
    "        Parameters\n",
    "        ---------\n",
    "        ligands\n",
    "            dict where keys are ligand IDs and values are ligands\n",
    "        k\n",
    "            number of clusters to initialize\n",
    "        Returns: List clusters with assigned ligands\n",
    "        \"\"\"\n",
    "        # choose k random ligands as centroids\n",
    "        clusters = random.sample(range(len(ligands)), k)\n",
    "        centroids = []\n",
    "        for i in range(k):\n",
    "            centroids.append(ligands[clusters[i]].onbits)\n",
    "            clusters[i] = [clusters[i]]\n",
    "        \n",
    "        #same_clusters = False\n",
    "        #same_iterations = 0\n",
    "        old_clusters = copy.deepcopy(clusters)\n",
    "        iters = 0\n",
    "\n",
    "        # Recompute centroids until they clusters haven't changed for 2 iterations\n",
    "        #while same_clusters == False:\n",
    "        while iters < 300:\n",
    "            new_clusters = copy.deepcopy(clusters)\n",
    "            new_centroids = copy.deepcopy(centroids)\n",
    "            for ligand in ligands.keys(): # Loop through ligands\n",
    "                distances = []\n",
    "                # Compute distance to each centroid\n",
    "                for centroid in centroids:\n",
    "                    dist = pc.calculate_distance(ligands[ligand].onbits, centroid)\n",
    "                    distances.append(dist)\n",
    "\n",
    "                # assign ligand to cluster with min distance (tie breaking?)\n",
    "                closest = distances.index(min(distances))\n",
    "                new_clusters[closest].append(ligand)\n",
    "                new_clusters[closest] = list(set(new_clusters[closest]))\n",
    "\n",
    "                # Add onbits to new centroids\n",
    "                new_centroids[closest].extend(ligands[ligand].onbits)\n",
    "                new_centroids[closest] = list(set(new_centroids[closest]))\n",
    "\n",
    "            # recalculate centroids \n",
    "            centroids = copy.deepcopy(new_centroids)\n",
    "\n",
    "            # Keep track of how many times the clusters have not changed\n",
    "            #if new_clusters == old_clusters:\n",
    "            #    same_iterations += 1\n",
    "            #if same_iterations == 10:\n",
    "            #    same_clusters = True\n",
    "            iters += 1\n",
    "            old_clusters = copy.deepcopy(new_clusters)\n",
    "\n",
    "        return new_clusters\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "\n",
    "def rand_index(ligands,clustering1, clustering2):\n",
    "    # Convert list of clusters to list of counts\n",
    "    c1 = [0] * len(ligands)\n",
    "    for i in range(len(clustering1)):\n",
    "        for j in range(len(clustering1[i])):\n",
    "            idx = clustering1[i][j]\n",
    "            c1[idx] = i\n",
    "        \n",
    "    c2 = [0] * len(ligands)\n",
    "    for i in range(len(clustering2)):\n",
    "        for j in range(len(clustering2[i])):\n",
    "            idx = clustering2[i][j]\n",
    "            c2[idx] = i\n",
    "                \n",
    "    # number of different pairs for each clustering\n",
    "    combos_c1 = comb(np.bincount(c1),2).sum()\n",
    "    combos_c2 = comb(np.bincount(c2),2).sum()\n",
    "    \n",
    "    # combine counts into one mat\n",
    "    mat = np.c_[(c1, c2)]\n",
    "    F_11 = 0\n",
    "    for i in range(len(clusters1)):\n",
    "        F_11 += comb(np.bincount(mat[mat[:, 0] == i, 1]), 2).sum()\n",
    "    F_01 = combos_c1 - F_11\n",
    "    F_10 = combos_c2 - F_11\n",
    "    F_00 = comb(len(A), 2) - F_11 - F_10 - F_01\n",
    "    return (F_11 + F_00)/(F_11 + F_01 + F_10 + F_00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering1 = [[0,1,3],[2,4],[5]]\n",
    "clustering2 = [[0,1,4],[2,3],[5]]\n",
    "ligands = [0]*6\n",
    "\n",
    "c1 = [0] * len(ligands)\n",
    "for i in range(len(clustering1)):\n",
    "    for j in range(len(clustering1[i])):\n",
    "        idx = clustering1[i][j]\n",
    "        c1[idx] = i\n",
    "\n",
    "c2 = [0] * len(ligands)\n",
    "for i in range(len(clustering2)):\n",
    "    for j in range(len(clustering2[i])):\n",
    "        idx = clustering2[i][j]\n",
    "        c2[idx] = i\n",
    "\n",
    "# number of different pairs for each clustering\n",
    "combos_c1 = comb(np.bincount(c1),2).sum()\n",
    "combos_c2 = comb(np.bincount(c2),2).sum()\n",
    "\n",
    "# combine counts into one mat\n",
    "mat = np.c_[(c1, c2)]\n",
    "F_11 = 0\n",
    "for i in range(len(clustering1)):\n",
    "    F_11 += comb(np.bincount(mat[mat[:, 0] == i, 1]), 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos_c1 + combos_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb(len(mat), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb(np.bincount(A[A[:, 0] == i, 1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_11\n",
    "for i in set(clusters):\n",
    "    comb(np.bincount(A[A[:, 0] == i, 1]), 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import comb\n",
    "def rand_index_score(clusters, classes):\n",
    "    tp_plus_fp = comb(np.bincount(clusters), 2).sum()\n",
    "    tp_plus_fn = comb(np.bincount(classes), 2).sum()\n",
    "    A = np.c_[(clusters, classes)]\n",
    "    tp = sum(comb(np.bincount(A[A[:, 0] == i, 1]), 2).sum()\n",
    "             for i in set(clusters))\n",
    "    fp = tp_plus_fp - tp\n",
    "    fn = tp_plus_fn - tp\n",
    "    tn = comb(len(A), 2) - tp - fp - fn\n",
    "    return (tp + tn) / (tp + fp + fn + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  inf, 1.   , 1.   , 0.875],\n",
       "       [1.   ,   inf, 0.8  , 1.   ],\n",
       "       [1.   , 0.8  ,   inf, 1.   ],\n",
       "       [0.875, 1.   , 1.   ,   inf]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = PartitionClustering()\n",
    "\n",
    "ligands = pc.get_ligands(4)\n",
    "\n",
    "dist = pc.distance_matrix(ligands)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [[1,4,5],[2,3]]\n",
    "c = [j for i in clusters for j in i]\n",
    "c.sort()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PartitionClustering()\n",
    "\n",
    "ligands = pc.get_ligands(10)\n",
    "pc.cluster(ligands,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose k random ligands as centroids\n",
    "clusters = random.sample(range(len(ligands)), k)\n",
    "centroids = []\n",
    "for i in range(k):\n",
    "    centroids.append(ligands[clusters[i]].onbits)\n",
    "    clusters[i] = [clusters[i]]\n",
    "\n",
    "same_clusters = False\n",
    "same_iterations = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters = copy.deepcopy(clusters)\n",
    "new_centroids = copy.deepcopy(centroids)\n",
    "\n",
    "for ligand in ligands.keys(): # Loop through ligands\n",
    "    distances = []\n",
    "    # Compute distance to each centroid\n",
    "    for centroid in centroids:\n",
    "        dist = pc.calculate_distance(ligands[ligand].onbits, centroid)\n",
    "        distances.append(dist)\n",
    "\n",
    "    # skip starting centroids\n",
    "    if min(distances) == 0:\n",
    "        continue\n",
    "\n",
    "    # assign ligand to cluster with min distance (tie breaking?)\n",
    "    closest = distances.index(min(distances))\n",
    "    new_clusters[closest].append(ligand)\n",
    "\n",
    "    # Add onbits to new centroids\n",
    "    new_centroids[closest].extend(ligands[ligand].onbits)\n",
    "    new_centroids[closest] = list(set(new_centroids[closest]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_clusters = clusters.copy()\n",
    "# recalculate centroids \n",
    "centroids = new_centroids\n",
    "\n",
    "# Keep track of how many times the clusters have not changed\n",
    "if new_clusters == old_clusters:\n",
    "    same_iterations += 1\n",
    "if same_iterations == 2:\n",
    "    same_clusters = True\n",
    "\n",
    "old_clusters = new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(\n",
    "    n_clusters=2, init='random',\n",
    "    n_init=10, max_iter=300, \n",
    "    tol=1e-04, random_state=0\n",
    ")\n",
    "y_km = km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "new_clusters = copy.deepcopy(clusters)\n",
    "new_clusters[1].append(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HierarchicalClustering()\n",
    "\n",
    "ligands = hc.get_ligands(4)\n",
    "\n",
    "pend([key])\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ligands)):\n",
    "    for j in range(len(ligands)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        dist[i,j] = hc.calculate_distance(ligands[i],ligands[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_i, min_j = np.unravel_index(np.argmin(dist), dist.shape)\n",
    "min_i, min_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the two ligands in clusters\n",
    "found_i = -1\n",
    "found_j = -1\n",
    "for idx in range(len(clusters)):\n",
    "    if (found_i >= 0 and found_j >= 0):\n",
    "        break\n",
    "    if found_i < 0 and min_i in clusters[idx]:\n",
    "        found_i = idx\n",
    "    if found_j < 0 and min_j in clusters[idx]:\n",
    "        found_j = idx\n",
    "\n",
    "# merge the clusters\n",
    "clusters[found_i]+= clusters[found_j]\n",
    "del clusters[found_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(ligands)):\n",
    "    if dist[min_i, idx] == np.inf:\n",
    "        continue\n",
    "    minimum = min(dist[min_i, idx], dist[min_j,idx])\n",
    "    dist[min_i, idx] = minimum\n",
    "    dist[idx, min_i] = minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[min_j, :] = np.inf\n",
    "dist[:, min_j] = np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HierarchicalClustering()\n",
    "\n",
    "ligands = hc.get_ligands(10)\n",
    "\n",
    "c = hc.cluster(ligands, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "dist = np.zeros((len(ligands),len(ligands)))\n",
    "for i in range(len(ligands)):\n",
    "    for j in range(len(ligands)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        dist[i,j] = hc.calculate_distance(ligands[i].onbits,ligands[j].onbits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(affinity=\"precomputed\", n_clusters=3,linkage=\"single\").fit_predict(dist)\n",
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(clustering == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
